{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q25bhk-GdO5g"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"과제5 CNN기반 영상분류문제\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWsfLCnKdXdF",
        "outputId": "45c1bcba-148e-4414-c627-c39383d18554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "reduced train/val size: 50000 2000 input shape: (32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "#x_train, _, y_train,_ = train_test_split(x_train, y_train, test_size=0.5, random_state=42)\n",
        "x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.8, random_state=42)\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#동일조건 유지해야 하는 변수(두 모델 모두 동일하게 적용해야 함)\n",
        "g_epoch = 80\n",
        "g_batch = 128\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "0RVBYP5IdrU9",
        "outputId": "f5f37089-3c24-4160-e84f-d21067d1c4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# to make this notebook's output stable across runs\n",
        "import sys\n",
        "\n",
        "print(sys.version)\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKNQysENdwi9",
        "outputId": "770b9685-e666-47db-82b7-9d19891f4a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              2305000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,275,906\n",
            "Trainable params: 3,275,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1000,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10,activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sosPPWVsd0fk",
        "outputId": "facbced3-b1ac-4e18-84d7-90abf351b03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "391/391 [==============================] - 16s 16ms/step - loss: 2.1611 - accuracy: 0.1947 - val_loss: 1.9965 - val_accuracy: 0.3070\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.8852 - accuracy: 0.3166 - val_loss: 1.9138 - val_accuracy: 0.3070\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.7594 - accuracy: 0.3623 - val_loss: 1.7949 - val_accuracy: 0.3515\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.6829 - accuracy: 0.3900 - val_loss: 1.7792 - val_accuracy: 0.3695\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.6187 - accuracy: 0.4137 - val_loss: 1.6647 - val_accuracy: 0.4055\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.5685 - accuracy: 0.4312 - val_loss: 1.7197 - val_accuracy: 0.3900\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.5259 - accuracy: 0.4479 - val_loss: 1.5950 - val_accuracy: 0.4315\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.4899 - accuracy: 0.4606 - val_loss: 1.5373 - val_accuracy: 0.4580\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.4593 - accuracy: 0.4744 - val_loss: 1.4891 - val_accuracy: 0.4670\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 1.4308 - accuracy: 0.4850 - val_loss: 1.4364 - val_accuracy: 0.4985\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.4081 - accuracy: 0.4951 - val_loss: 1.4351 - val_accuracy: 0.4960\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.3853 - accuracy: 0.5029 - val_loss: 1.4073 - val_accuracy: 0.5055\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.3638 - accuracy: 0.5106 - val_loss: 1.4012 - val_accuracy: 0.5080\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.3431 - accuracy: 0.5207 - val_loss: 1.3814 - val_accuracy: 0.5160\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.3244 - accuracy: 0.5280 - val_loss: 1.3455 - val_accuracy: 0.5330\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.3010 - accuracy: 0.5401 - val_loss: 1.3242 - val_accuracy: 0.5390\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2888 - accuracy: 0.5415 - val_loss: 1.3222 - val_accuracy: 0.5415\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2713 - accuracy: 0.5503 - val_loss: 1.2550 - val_accuracy: 0.5620\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2546 - accuracy: 0.5560 - val_loss: 1.2631 - val_accuracy: 0.5570\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2395 - accuracy: 0.5633 - val_loss: 1.2587 - val_accuracy: 0.5630\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2250 - accuracy: 0.5675 - val_loss: 1.2411 - val_accuracy: 0.5695\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.2123 - accuracy: 0.5728 - val_loss: 1.2528 - val_accuracy: 0.5590\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1963 - accuracy: 0.5786 - val_loss: 1.2267 - val_accuracy: 0.5725\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1861 - accuracy: 0.5803 - val_loss: 1.1881 - val_accuracy: 0.5880\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1716 - accuracy: 0.5874 - val_loss: 1.1908 - val_accuracy: 0.5855\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1586 - accuracy: 0.5933 - val_loss: 1.1741 - val_accuracy: 0.5845\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1481 - accuracy: 0.5953 - val_loss: 1.1632 - val_accuracy: 0.5955\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1358 - accuracy: 0.6020 - val_loss: 1.1411 - val_accuracy: 0.6000\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1227 - accuracy: 0.6058 - val_loss: 1.1306 - val_accuracy: 0.6055\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1140 - accuracy: 0.6088 - val_loss: 1.1292 - val_accuracy: 0.6050\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.1017 - accuracy: 0.6124 - val_loss: 1.1139 - val_accuracy: 0.6110\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0924 - accuracy: 0.6165 - val_loss: 1.0986 - val_accuracy: 0.6185\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0849 - accuracy: 0.6194 - val_loss: 1.1026 - val_accuracy: 0.6150\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0734 - accuracy: 0.6242 - val_loss: 1.1166 - val_accuracy: 0.6005\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0609 - accuracy: 0.6301 - val_loss: 1.0867 - val_accuracy: 0.6245\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0528 - accuracy: 0.6330 - val_loss: 1.0998 - val_accuracy: 0.6135\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0408 - accuracy: 0.6361 - val_loss: 1.0532 - val_accuracy: 0.6385\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0349 - accuracy: 0.6384 - val_loss: 1.0598 - val_accuracy: 0.6250\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0242 - accuracy: 0.6414 - val_loss: 1.0440 - val_accuracy: 0.6335\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0158 - accuracy: 0.6446 - val_loss: 1.0442 - val_accuracy: 0.6320\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 1.0051 - accuracy: 0.6483 - val_loss: 1.0408 - val_accuracy: 0.6295\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9980 - accuracy: 0.6514 - val_loss: 1.0359 - val_accuracy: 0.6455\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9894 - accuracy: 0.6551 - val_loss: 1.0115 - val_accuracy: 0.6460\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9786 - accuracy: 0.6588 - val_loss: 1.0143 - val_accuracy: 0.6385\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9709 - accuracy: 0.6598 - val_loss: 0.9987 - val_accuracy: 0.6470\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9618 - accuracy: 0.6632 - val_loss: 1.0237 - val_accuracy: 0.6400\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9532 - accuracy: 0.6662 - val_loss: 0.9858 - val_accuracy: 0.6530\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9474 - accuracy: 0.6688 - val_loss: 0.9905 - val_accuracy: 0.6500\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9383 - accuracy: 0.6734 - val_loss: 1.0045 - val_accuracy: 0.6430\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9334 - accuracy: 0.6751 - val_loss: 0.9715 - val_accuracy: 0.6435\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9206 - accuracy: 0.6784 - val_loss: 0.9841 - val_accuracy: 0.6515\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9145 - accuracy: 0.6823 - val_loss: 0.9829 - val_accuracy: 0.6550\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.9086 - accuracy: 0.6843 - val_loss: 0.9596 - val_accuracy: 0.6625\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8995 - accuracy: 0.6889 - val_loss: 0.9468 - val_accuracy: 0.6610\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8907 - accuracy: 0.6907 - val_loss: 0.9417 - val_accuracy: 0.6640\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8850 - accuracy: 0.6916 - val_loss: 0.9411 - val_accuracy: 0.6620\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8747 - accuracy: 0.6957 - val_loss: 0.9596 - val_accuracy: 0.6645\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8716 - accuracy: 0.6960 - val_loss: 0.9246 - val_accuracy: 0.6745\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8632 - accuracy: 0.7015 - val_loss: 0.9320 - val_accuracy: 0.6765\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8547 - accuracy: 0.7041 - val_loss: 0.9200 - val_accuracy: 0.6770\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8511 - accuracy: 0.7028 - val_loss: 0.9110 - val_accuracy: 0.6825\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8389 - accuracy: 0.7080 - val_loss: 0.9086 - val_accuracy: 0.6885\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8342 - accuracy: 0.7100 - val_loss: 0.9174 - val_accuracy: 0.6825\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8252 - accuracy: 0.7122 - val_loss: 0.8907 - val_accuracy: 0.6855\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8208 - accuracy: 0.7152 - val_loss: 0.8845 - val_accuracy: 0.6905\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8141 - accuracy: 0.7183 - val_loss: 0.8894 - val_accuracy: 0.6895\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8053 - accuracy: 0.7221 - val_loss: 0.8785 - val_accuracy: 0.6870\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.8008 - accuracy: 0.7218 - val_loss: 0.9099 - val_accuracy: 0.6815\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7970 - accuracy: 0.7246 - val_loss: 0.8853 - val_accuracy: 0.6960\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7861 - accuracy: 0.7284 - val_loss: 0.8822 - val_accuracy: 0.7030\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7817 - accuracy: 0.7277 - val_loss: 0.8897 - val_accuracy: 0.6890\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7734 - accuracy: 0.7333 - val_loss: 0.8572 - val_accuracy: 0.6995\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7702 - accuracy: 0.7314 - val_loss: 0.8544 - val_accuracy: 0.7025\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7615 - accuracy: 0.7364 - val_loss: 0.8540 - val_accuracy: 0.6975\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7545 - accuracy: 0.7376 - val_loss: 0.8481 - val_accuracy: 0.6990\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7518 - accuracy: 0.7406 - val_loss: 0.8515 - val_accuracy: 0.7020\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7459 - accuracy: 0.7403 - val_loss: 0.8367 - val_accuracy: 0.7100\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7390 - accuracy: 0.7444 - val_loss: 0.8359 - val_accuracy: 0.7085\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7331 - accuracy: 0.7457 - val_loss: 0.8415 - val_accuracy: 0.6950\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7276 - accuracy: 0.7469 - val_loss: 0.8351 - val_accuracy: 0.7150\n",
            "Baseline 정확률은 71.79999947547913\n"
          ]
        }
      ],
      "source": [
        "  hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline 정확률은\",g_org_res[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOQ_LIzfd4Gs",
        "outputId": "5135c1d2-afee-47fc-a5f5-1c1de4f469f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,786,858\n",
            "Trainable params: 14,785,834\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "no_class = 10\n",
        "\n",
        "# for transfer learning only\n",
        "from tensorflow.keras.applications import VGG16\n",
        "he = tf.keras.initializers.HeNormal()\n",
        "\n",
        "# for transfer learning only\n",
        "transfermodel = VGG16(weights='imagenet',include_top=False,\n",
        "                    input_shape=input_shape)\n",
        "#base_model.trainable=False     # it's up to you\n",
        "# your model architecture\n",
        "model=Sequential()\n",
        "model.add(transfermodel)    # for transfer learning only\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "# model.add(Flatten())        # for transfer learning only\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(no_class, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MCK-uyceFZc",
        "outputId": "e8760213-6380-4244-e863-e6ff4a636638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "391/391 [==============================] - 23s 56ms/step - loss: 1.2176 - accuracy: 0.6050 - val_loss: 0.8878 - val_accuracy: 0.7080\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.6682 - accuracy: 0.7808 - val_loss: 0.7178 - val_accuracy: 0.7620\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.5053 - accuracy: 0.8328 - val_loss: 0.6220 - val_accuracy: 0.7955\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 23s 58ms/step - loss: 0.3961 - accuracy: 0.8703 - val_loss: 0.6146 - val_accuracy: 0.8085\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 23s 58ms/step - loss: 0.3072 - accuracy: 0.8994 - val_loss: 0.6332 - val_accuracy: 0.7995\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.2327 - accuracy: 0.9246 - val_loss: 0.6013 - val_accuracy: 0.8225\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.1631 - accuracy: 0.9495 - val_loss: 0.5780 - val_accuracy: 0.8320\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.1096 - accuracy: 0.9678 - val_loss: 0.6383 - val_accuracy: 0.8255\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0710 - accuracy: 0.9803 - val_loss: 0.6551 - val_accuracy: 0.8285\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0491 - accuracy: 0.9870 - val_loss: 0.6787 - val_accuracy: 0.8305\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0387 - accuracy: 0.9897 - val_loss: 0.7176 - val_accuracy: 0.8250\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0258 - accuracy: 0.9936 - val_loss: 0.7151 - val_accuracy: 0.8300\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0252 - accuracy: 0.9930 - val_loss: 0.7421 - val_accuracy: 0.8320\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.8470 - val_accuracy: 0.8245\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.8440 - val_accuracy: 0.8285\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.8443 - val_accuracy: 0.8305\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.8663 - val_accuracy: 0.8280\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.8723 - val_accuracy: 0.8285\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.8858 - val_accuracy: 0.8285\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.9397 - val_accuracy: 0.8225\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.9233 - val_accuracy: 0.8385\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.9485 - val_accuracy: 0.8190\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.8752 - val_accuracy: 0.8280\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.9787 - val_accuracy: 0.8325\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.9864 - val_accuracy: 0.8310\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.9882 - val_accuracy: 0.8230\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.9765 - val_accuracy: 0.8230\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.9804 - val_accuracy: 0.8290\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.9983 - val_accuracy: 0.8245\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.1845 - val_accuracy: 0.8015\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.9761 - val_accuracy: 0.8345\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.9802 - val_accuracy: 0.8305\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 1.0003 - val_accuracy: 0.8305\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 1.0400 - val_accuracy: 0.8125\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.8711 - val_accuracy: 0.8420\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.9323 - val_accuracy: 0.8445\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.0083 - val_accuracy: 0.8375\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 1.0746 - val_accuracy: 0.8295\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.1388 - val_accuracy: 0.8175\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 1.0023 - val_accuracy: 0.8305\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.0333 - val_accuracy: 0.8345\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.0420 - val_accuracy: 0.8320\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.9245 - val_accuracy: 0.8445\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.9382 - val_accuracy: 0.8435\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.0110 - val_accuracy: 0.8365\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.9800 - val_accuracy: 0.8375\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.0345 - val_accuracy: 0.8375\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.9765 - val_accuracy: 0.8460\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.9288 - val_accuracy: 0.8490\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 1.2037 - val_accuracy: 0.8080\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.0451 - val_accuracy: 0.8225\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.9412 - val_accuracy: 0.8475\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.0428 - val_accuracy: 0.8305\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 1.1510 - val_accuracy: 0.8200\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.9690 - val_accuracy: 0.8450\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.0220 - val_accuracy: 0.8335\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 1.0499 - val_accuracy: 0.8340\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.1995 - val_accuracy: 0.8140\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.9529 - val_accuracy: 0.8340\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.9316 - val_accuracy: 0.8495\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.9347 - val_accuracy: 0.8490\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.0474 - val_accuracy: 0.8360\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.9817 - val_accuracy: 0.8440\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.1097 - val_accuracy: 0.8310\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 1.0410 - val_accuracy: 0.8475\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.0778 - val_accuracy: 0.8380\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.9575 - val_accuracy: 0.8450\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.0040 - val_accuracy: 0.8480\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.0164 - val_accuracy: 0.8445\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.9687 - val_accuracy: 0.8480\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 1.2423 - val_accuracy: 0.8235\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.9527 - val_accuracy: 0.8500\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.9469 - val_accuracy: 0.8525\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.0730 - val_accuracy: 0.8410\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.0497 - val_accuracy: 0.8420\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.0200 - val_accuracy: 0.8395\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.0959 - val_accuracy: 0.8395\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.0379 - val_accuracy: 0.8350\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.9973 - val_accuracy: 0.8450\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.9847 - val_accuracy: 0.8460\n",
            "Baseline vs yours:  71.79999947547913 85.04999876022339\n"
          ]
        }
      ],
      "source": [
        "hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "yours=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pedkKPByVEn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KwL0RgiWJ0ES"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "homework_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}